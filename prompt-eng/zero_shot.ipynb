{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting\n",
    "\n",
    "Zero-shot prompting refers to a technique in prompt engineering where you provide a model with a task without any prior examples. The model is expected to understand and generate a response or complete the task purely based on the given instruction.\n",
    "\n",
    "In other words, the model is given \"zero\" prior training examples or demonstrations in the prompt and relies on its pre-trained knowledge to infer what is needed.\n",
    "\n",
    "## References:\n",
    "* [Wei et al. (2022)](https://arxiv.org/pdf/2109.01652.pdf): demonstrate how instruction tuning improves zero-shot learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fzero_shot.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate this, we need to know that the logarithm of 2 (base 10) is approximately 0.301.\n",
      "\n",
      "So,\n",
      "\n",
      "984 * log(2) ≈ 984 * 0.301\n",
      "≈ 295.584\n",
      "Time taken: 5.399s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## ZERO SHOT PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"What is 984 * log(2)\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "PROMPT = MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to improve it?\n",
    "\n",
    "* **Use Clear and Concise Instructions**: Be specific about the task and desired format.\n",
    "    * Bad Prompt: “Summarize this.”\n",
    "    * Good Prompt: “Summarize this paragraph in one sentence.”\n",
    "* **Add Context**: Providing background can help the model interpret ambiguous prompts better.\n",
    "* **Specify Output Format**: If a particular structure is needed, describe it in the instruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nGenerate a prompt to generate requirement analysis for a Discord chatbot that:\\n- Enable data scientists and business analysts to efficiently locate and extract relevant data from company databases to answer specific queries and generate reports.\\n', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 500, 'num_predict': 500}}\n",
      "Generated Prompt: Here's a prompt for generating a requirement analysis for a Discord chatbot that enables data scientists and business analysts to efficiently locate and extract relevant data from company databases:\n",
      "\n",
      "**Project Title:** \"Data Insights Bot\" - A Discord-based Data Extraction and Reporting Platform\n",
      "\n",
      "**Objective:**\n",
      "\n",
      "Design a Discord-based chatbot that streamlines the process of extracting relevant data from company databases, facilitating efficient querying and reporting for data scientists and business analysts. The bot should provide an intuitive interface to discover, extract, and visualize data, ultimately supporting informed decision-making and data-driven insights.\n",
      "\n",
      "**Functional Requirements:**\n",
      "\n",
      "1. **Data Discovery**\n",
      "\t* Users can search for specific keywords or phrases within the database to find relevant data points.\n",
      "\t* The bot provides a list of potential matches, along with their corresponding data fields (e.g., date range, location).\n",
      "2. **Data Extraction**\n",
      "\t* Upon selecting a match, the bot extracts the required data from the company databases, integrating with various data sources (e.g., CRM, ERP, Excel files).\n",
      "3. **Data Preprocessing**\n",
      "\t* The extracted data is preprocessed to ensure consistency and standardization.\n",
      "4. **Querying and Filtering**\n",
      "\t* Users can apply filters to refine their query results based on predefined criteria (e.g., date range, location, user groups).\n",
      "5. **Reporting and Visualization**\n",
      "\t* The bot generates interactive visualizations (e.g., charts, graphs) to present the extracted data in an easily understandable format.\n",
      "6. **Data Storage and Management**\n",
      "\t* A centralized database stores all queried and reported data for historical reference and analysis.\n",
      "\n",
      "**Non-Functional Requirements:**\n",
      "\n",
      "1. **Security**: Ensure all interactions are encrypted and protected with user authentication and authorization mechanisms.\n",
      "2. **Scalability**: Design the chatbot to handle a large number of users and queries without impacting performance or response times.\n",
      "3. **Integrations**: Integrate with various company databases and tools, as well as third-party services for data enrichment (e.g., natural language processing, sentiment analysis).\n",
      "4. **User Experience**:\n",
      "\t* Provide intuitive search functionality and clear instructions for users to navigate the chatbot.\n",
      "\t* Offer customization options for user groups or roles.\n",
      "\n",
      "**Assumptions and Dependencies:**\n",
      "\n",
      "1. Company databases and tools are available and accessible via APIs or direct connections.\n",
      "2. User authentication mechanisms (e.g., OAuth, SAML) are in place for secure interaction.\n",
      "\n",
      "Please note that this is a general\n",
      "First level processing time: 9.413s\n",
      "{'model': 'llama3.2:latest', 'prompt': 'Here\\'s a prompt for generating a requirement analysis for a Discord chatbot that enables data scientists and business analysts to efficiently locate and extract relevant data from company databases:\\n\\n**Project Title:** \"Data Insights Bot\" - A Discord-based Data Extraction and Reporting Platform\\n\\n**Objective:**\\n\\nDesign a Discord-based chatbot that streamlines the process of extracting relevant data from company databases, facilitating efficient querying and reporting for data scientists and business analysts. The bot should provide an intuitive interface to discover, extract, and visualize data, ultimately supporting informed decision-making and data-driven insights.\\n\\n**Functional Requirements:**\\n\\n1. **Data Discovery**\\n\\t* Users can search for specific keywords or phrases within the database to find relevant data points.\\n\\t* The bot provides a list of potential matches, along with their corresponding data fields (e.g., date range, location).\\n2. **Data Extraction**\\n\\t* Upon selecting a match, the bot extracts the required data from the company databases, integrating with various data sources (e.g., CRM, ERP, Excel files).\\n3. **Data Preprocessing**\\n\\t* The extracted data is preprocessed to ensure consistency and standardization.\\n4. **Querying and Filtering**\\n\\t* Users can apply filters to refine their query results based on predefined criteria (e.g., date range, location, user groups).\\n5. **Reporting and Visualization**\\n\\t* The bot generates interactive visualizations (e.g., charts, graphs) to present the extracted data in an easily understandable format.\\n6. **Data Storage and Management**\\n\\t* A centralized database stores all queried and reported data for historical reference and analysis.\\n\\n**Non-Functional Requirements:**\\n\\n1. **Security**: Ensure all interactions are encrypted and protected with user authentication and authorization mechanisms.\\n2. **Scalability**: Design the chatbot to handle a large number of users and queries without impacting performance or response times.\\n3. **Integrations**: Integrate with various company databases and tools, as well as third-party services for data enrichment (e.g., natural language processing, sentiment analysis).\\n4. **User Experience**:\\n\\t* Provide intuitive search functionality and clear instructions for users to navigate the chatbot.\\n\\t* Offer customization options for user groups or roles.\\n\\n**Assumptions and Dependencies:**\\n\\n1. Company databases and tools are available and accessible via APIs or direct connections.\\n2. User authentication mechanisms (e.g., OAuth, SAML) are in place for secure interaction.\\n\\nPlease note that this is a general', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 500, 'num_predict': 500}}\n",
      "\n",
      "Final Requirement Analysis: Here is the rewritten response:\n",
      "\n",
      "The chatbot will utilize a scalable and secure architecture to handle a large number of users and queries. The following components will be integrated to achieve these goals:\n",
      "\n",
      "1. **Database**: A centralized database will store all queried and reported data for historical reference and analysis.\n",
      "2. **API Gateway**: An API gateway will manage incoming requests, authenticate users, and route them to the relevant chatbot component.\n",
      "3. **Chatbot Component**: The chatbot component will utilize natural language processing (NLP) and machine learning algorithms to understand user input and generate responses.\n",
      "4. **Data Enrichment**: Third-party services for data enrichment, such as natural language processing and sentiment analysis, will be integrated to enhance the chatbot's capabilities.\n",
      "\n",
      "**Security Measures**\n",
      "\n",
      "1. **Encryption**: All interactions will be encrypted using secure communication protocols (e.g., TLS).\n",
      "2. **User Authentication**: User authentication mechanisms (e.g., OAuth, SAML) will be implemented to ensure secure interaction.\n",
      "3. **Access Control**: Role-based access control will be enforced to restrict access to sensitive data and features.\n",
      "\n",
      "**Scalability**\n",
      "\n",
      "1. **Cloud-based Infrastructure**: The chatbot's infrastructure will be built on cloud-based platforms (e.g., AWS, Azure) to ensure scalability and flexibility.\n",
      "2. **Load Balancing**: Load balancing mechanisms will be implemented to distribute incoming traffic efficiently and prevent single-point failure.\n",
      "3. **Caching**: Caching mechanisms will be employed to reduce database queries and improve response times.\n",
      "\n",
      "**Data Management**\n",
      "\n",
      "1. **Data Storage**: The centralized database will store user data, chatbot logs, and analytics data.\n",
      "2. **Data Backup**: Regular backups will be performed to ensure data integrity and availability.\n",
      "3. **Data Analytics**: Data analytics tools will be integrated to provide insights on user behavior and chatbot performance.\n",
      "\n",
      "**Development and Testing**\n",
      "\n",
      "1. **Agile Development Methodology**: An agile development methodology (e.g., Scrum, Kanban) will be adopted to ensure rapid iteration and feedback loops.\n",
      "2. **Unit Testing**: Unit testing will be performed to ensure individual components function correctly before integrating them into the chatbot.\n",
      "3. **Integration Testing**: Integration testing will be conducted to verify interactions between different components are seamless and error-free.\n",
      "\n",
      "By incorporating these components, security measures, scalability features, data management practices, and development methodologies, the chatbot will provide a secure, scalable, and efficient solution for users.\n",
      "Second level processing time: 9.442s\n"
     ]
    }
   ],
   "source": [
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) User's Initial Request for the Chatbot\n",
    "USER_REQUEST = \"\"\"\n",
    "Generate a prompt to generate requirement analysis for a Discord chatbot that:\n",
    "- Enable data scientists and business analysts to efficiently locate and extract relevant data from company databases to answer specific queries and generate reports.\n",
    "\"\"\"\n",
    "\n",
    "#### (2) First-Level Automation: Generate a structured prompt\n",
    "first_payload = create_payload(\n",
    "    target=\"ollama\",\n",
    "    model=\"llama3.2:latest\",\n",
    "    prompt=USER_REQUEST,\n",
    "    temperature=1.0,\n",
    "    num_ctx=500,\n",
    "    num_predict=500,\n",
    ")\n",
    "\n",
    "# Send first request to generate the refined prompt\n",
    "first_time, first_response = model_req(payload=first_payload)\n",
    "print(\"Generated Prompt:\", first_response)\n",
    "if first_time:\n",
    "    print(f\"First level processing time: {first_time}s\")\n",
    "\n",
    "#### (3) Second-Level Automation: Use the Generated Prompt for Final Requirement Analysis\n",
    "second_payload = create_payload(\n",
    "    target=\"ollama\",\n",
    "    model=\"llama3.2:latest\",\n",
    "    prompt=first_response,  # Use the generated prompt\n",
    "    temperature=1.0,\n",
    "    num_ctx=500,\n",
    "    num_predict=500,\n",
    ")\n",
    "\n",
    "# Send second request to generate the requirement analysis\n",
    "second_time, second_response = model_req(payload=second_payload)\n",
    "print(\"\\nFinal Requirement Analysis:\", second_response)\n",
    "if second_time:\n",
    "    print(f\"Second level processing time: {second_time}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
