{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting\n",
    "\n",
    "Zero-shot prompting refers to a technique in prompt engineering where you provide a model with a task without any prior examples. The model is expected to understand and generate a response or complete the task purely based on the given instruction.\n",
    "\n",
    "In other words, the model is given \"zero\" prior training examples or demonstrations in the prompt and relies on its pre-trained knowledge to infer what is needed.\n",
    "\n",
    "## Pros:\n",
    "\n",
    "* **Efficiency**: Zero-shot prompting eliminates the need to provide multiple examples, saving time when formulating instructions.\n",
    "* **Scalability**: It is highly scalable for tasks like classification, summarization, or translation where predefined examples may not always be necessary.\n",
    "* **Broad Generalization**: Models, particularly large ones like GPT, can generalize across many domains without being specifically trained on each task.\n",
    "\n",
    "## Cons:\n",
    "\n",
    "* **Ambiguity**: Without examples, the model may misinterpret vague or poorly defined instructions.\n",
    "* **Lower Accuracy**: Zero-shot prompting can be less reliable than techniques like few-shot prompting, which provide the model with examples.\n",
    "* **Context Dependency**: The model's performance depends heavily on how clear and specific the instruction is.\n",
    "\n",
    "## Improving results:\n",
    "* **Use Clear and Concise Instructions**: Be specific about the task and desired format.\n",
    "    * Bad Prompt: “Summarize this.”\n",
    "    * Good Prompt: “Summarize this paragraph in one sentence.”\n",
    "* **Add Context**: Providing background can help the model interpret ambiguous prompts better.\n",
    "* **Specify Output Format**: If a particular structure is needed, describe it in the instruction.\n",
    "\n",
    "## References:\n",
    "* [Wei et al. (2022)](https://arxiv.org/pdf/2109.01652.pdf): demonstrate how instruction tuning improves zero-shot learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fzero_shot.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 1 = 2\n",
      "Time taken: 0.604s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## ZERO SHOT PROMPTING\n",
    "##\n",
    "\n",
    "from pipeline import create_payload, model_req\n",
    "\n",
    "# Simulate the inbounding message\n",
    "# Note: this is the message coming from the interface.\n",
    "MESSAGE = \"1 + 1\"\n",
    "\n",
    "# Simulatte the Prompt Engineering Technique you want to apply\n",
    "PROMPT = MESSAGE \n",
    "\n",
    "# Configure your payload (optional)\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(model=\"llama3.2\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
